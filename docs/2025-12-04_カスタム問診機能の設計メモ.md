# カスタム問診機能の設計メモ

## ユーザ・シナリオ

- 管理者は、カスタム問診を作成できる
- 相談者は、カスタム問診を利用してヒアリングを受けることができる

## 登場オブジェクト

- 問診
  - 複数の項目で構成される
- 項目
  - 相談者から聞き出したいこと
- 報告
  - 問診の一通りの項目に関する情報が集まったあと、生成されるもの

## メモ

- Google Formsでフォームをつくる感じで、カスタム問診を作成できる
- 相談者が自力で作文してフォームに回答を埋めていくのではなく、LLMがひとつずつ聞き出す形で情報を集めていく
- 項目は自由記述だが、LLMが聞き方の工夫として選択肢を提示することもある（例：「1から10でいうと、どれくらいですか？」）

## 報告のビュー

- 管理者向け: 複数の相談者の報告をテーブルで一覧できるビュー
- 相談者向け: 印刷しやすいシンプルなドキュメント形式

## モデル設計

```
Intake (問診)
├── has_many :intake_items
├── has_many :intake_sessions
├── title: 問診のタイトル
└── description: 説明

IntakeItem (項目)
├── belongs_to :intake
├── name: 項目名
├── description: LLMへの指示（どう聞き出すか）
└── position: 並び順

IntakeSession (セッション)
├── belongs_to :intake
├── belongs_to :member
├── has_many :intake_messages
├── has_many :intake_responses
├── has_one :intake_report
└── status: 進行状況 (in_progress / completed)

IntakeMessage (対話ログ)
├── belongs_to :intake_session
├── role: assistant / user
└── content: メッセージ内容

IntakeResponse (回答)
├── belongs_to :intake_session
├── belongs_to :intake_item
└── content: 聞き出した内容

IntakeReport (報告)
├── belongs_to :intake_session
└── generated_at: 生成日時
```

## 対話フロー（ストリーミング）

参考: `ai-chat-stream-prototyping` ブランチの試作

```
1. 相談者が IntakeSession を開始
   └── IntakeSession.create!(intake:, member:, status: :in_progress)

2. LLM が最初の項目について質問（ストリーミング）
   ├── SSE で文字を逐次送信
   └── 完了後 IntakeMessage.create!(role: :assistant, content: ...)

3. 相談者が回答
   └── IntakeMessage.create!(role: :user, content: ...)

4. LLM が回答を解析
   ├── Tool Use で IntakeResponse を抽出・保存
   ├── 次の項目があれば → 2 へ戻る
   └── 全項目完了なら → 5 へ

5. IntakeReport 生成
   └── IntakeSession.update!(status: :completed)
```

### コントローラ設計

```ruby
IntakeSessionsController
├── create    # セッション開始
├── stream    # SSE エンドポイント（ActionController::Live）
└── show      # 結果表示

IntakeReportsController
├── index     # 管理者向け一覧（テーブル）
└── show      # 個別の報告書（印刷用）
```

### LLM Tool Use

LLM が対話中に使うツール:

```ruby
record_response(item_name:, content:)
# → IntakeResponse を保存

complete_intake
# → 全項目完了を宣言、Report 生成へ
```

### Intake::AgentLoop

既存の `Llm::AgentLoop` は Discord 特化のため、Intake 用に別途作成する。

**Llm::AgentLoop との違い:**

| 項目 | Llm::AgentLoop | Intake::AgentLoop |
|------|----------------|-------------------|
| ツール | Discord系（検索、チャンネル情報等） | Intake系（record_response, complete_intake） |
| 対話形式 | 1メッセージ → 応答完了 | 複数ターン（相談者の返答を待つ） |
| ストリーミング | 非対応（同期） | SSE 対応 |
| 状態管理 | なし | IntakeSession を保持 |

```ruby
module Intake
  class AgentLoop
    def initialize(session:, on_delta:)
      @session = session
      @on_delta = on_delta  # SSE ストリーミング用コールバック
      @tools = [
        Intake::Tools::RecordResponse.new(session),
        Intake::Tools::CompleteIntake.new(session)
      ]
    end

    # 相談者のメッセージを処理して、LLMの応答をストリーミング
    def process_user_message(content)
      # 1. IntakeMessage(user) を保存
      # 2. 会話履歴を構築
      # 3. LLM にストリーミングリクエスト
      #    - on_delta で文字を逐次送信
      #    - Tool Use があれば実行
      # 4. IntakeMessage(assistant) を保存
    end

    private

    def build_messages
      # IntakeMessage から Claude API 用の messages 配列を構築
    end

    def system_prompt
      # Intake + IntakeItems からシステムプロンプトを生成
    end
  end
end
```

### システムプロンプト（イメージ）

```
あなたは問診を行うアシスタントです。
以下の項目について、相談者から情報を聞き出してください。

【項目】
{{#each intake_items}}
- {{name}}: {{description}}
{{/each}}

- 1項目ずつ丁寧に聞いてください
- 十分な情報が得られたら record_response ツールで記録してください
- すべての項目が完了したら complete_intake を呼んでください
```

### LLMモデル選択

| 用途 | モデル | 理由 |
|------|--------|------|
| ヒアリング（対話） | Haiku | 高速・低コスト、レスポンス重視 |
| レポート作成 | Opus | 高品質な文章生成 |

## 将来の拡張

- ゲスト向けに開放して、ログインなしでも利用できるようにするかも
  - その際は IntakeSession に guest_token 等を追加して識別する
- プライバシーモード: IntakeReport 作成後に IntakeMessage を削除する選択肢
  - 「対話ログはサーバに保存されません（報告書作成後に削除）」的な説明
